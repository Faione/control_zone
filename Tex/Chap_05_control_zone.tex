\chapter{调度动态可定制沙箱实现}\label{chap:control_zone}

为解决单一调度机制与多样混部场景的问题，本章设计实现了Contorl Zone，一种面向混部场景的调度动态可定制沙箱。Control Zone基于KVM虚拟机实现，能够将Control Tower任务调度策略容器与混部应用协同部署。Control Zone允许将Control Tower调度器与混部应用协同部署。一方面，能够针对不同混部场景自由地选择合适的Control Tower调度器。另一方面，能够随混部应用的变化在运行时对Control Tower调度器动态修改。同时，还支持通过软硬件手段来隔离不同Control Zone的资源。

\section{Control Zone设计}

% 概述 -> 设计思路

% 介绍 Control Zone 的概念
% - 面对什么场景
% - 存在哪些问题
%   - 复杂的硬件环境
%   - 复杂的软件环境
% - 针对每个问题的解决方式
% - 设计目标

在航空领域，Control Zone指受控空域的一部分，通常在机场的周围，保护进出机场的的空中交通。Control Zone中依赖Control Tower进行客机起降的调度。本文借用Control Zone概念设计沙箱系统，在外层提供足够强的隔离性，而在内层则提供运行时可定制的任务调度框架Control Tower。Control Zone包含如下特性：

\begin{itemize}
    \item \textbf{轻量级虚拟机}：Control Zone使用虚拟机来提供更强的隔离性，而轻量化体现在两方面，一方面采用轻量化的Hypervisor，提供更快启动速度和更少的内存占用， 另一方使用最小化Guest内核及精简根文件系统，提供快速的系统引导与基本的系统功能。
    \item \textbf{容器化的任务}：Control Zone包含一个最小化的容器环境与容器运行时，支持大量容器化应用的运行，同时容器镜像与目录文件能够在不同的Control Zone之间共享，支持跨Control Zone的任务协作。
    \item \textbf{可动态定制的调度器}：Control Zone支持Control Tower调度框架，运行以容器方式打包的调度策略。Control Zone提供了基础的调度策略容器，同时，调度策略容器与任务容器的管理方式相同，同样支持运行时的修改与切换。
    \item \textbf{可观测性基础设施}：沙箱系统包含了一个围绕虚拟机的可观测性系统，能够从Host、Hypervisor、App三个层次以虚拟机为粒度采集丰富的指标，并提供实时监测与离线分析功能来全面地分析虚拟机及其中任务的性能。
\end{itemize}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{controlzone_arch}
    \bicaption{\quad Control Zone基本架构}{\quad Control Zone Architectural}
    \label{fig:controlzone_arch}
\end{figure}
 
Control Zone整体架构如图~\ref{fig:controlzone_arch}所示，其中管理器负责进行Control Zone的管理，提供隔离环境的定制能力，并可以根据混部任务的属性动态地对Control Tower调度器进行修改。除此之外，可观测性基础能够与各层次的系统组件交互，以采集全面的虚拟机指标信息。

针对混部场景下的硬件特性差异的挑战。Control Zone一方面能够利用虚拟化提供的抽象层屏蔽底层硬件的差异，另一方面则根据配置的硬件特性选择合适的Control Tower任务调度策略。同时，在硬件特性变化时，Control Zone任务调度策略可以同步修改，而无需中断虚拟机的执行。

针对混部场景下软件需求差异的挑战。首先，Control Zone可以针对高优先级任务的特性，匹配的合适的内核调度配置来满足任务在响应度或吞吐量上的需求。其次，针对混部场景的特性，能够进一步选择或定制合适的Control Tower调度器来进行QoS保障。同时，考虑混部应用的负载的动态特性，一方面可以通过eBPF监测应用的负载，另一方面可以在不同的阶段切换不同的Control Tower调度器来实现不同的调度目标。

\section{Control Zone实现}

\subsection{Control Zone组成}

% 优化图例
% 使用中文名称，体现功能
% Control Zone组成，阐述各个组成部分所做的功能，希望实现的目标
% - czctrl: Control Zone管理
% - czdaemon: 容器管理
%   - chsd: 调度策略管理
% - observity: 可观测性

调度动态可定制沙箱包括Control Zone管理、应用管理及可观测性三个主要部分。如图~\ref{fig:cz_components}所示，用户通过czyaml配置文件来定义一个Control Zone，而Control Zone的管理主要czctrl、czmanager及虚拟机监视器三个组件协作完成。每个Control Zone都运行有一个czdaemon，并与czctrl、czmanager协作实现应用管理。可观测性沿用了第3章中设计的在线指标监测系统，并与czmanager的协作完成对于虚拟机的监控。镜像存储服务负责管理OCI镜像，并在Control Zone运行的各个阶段中提供镜像存储服务。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{cz_components}
    \bicaption{\quad Control Zone组件结构}{\quad Components of Control Zone}
    \label{fig:cz_components}
\end{figure}

\begin{itemize}
    \item \textbf{czyaml}：Control Zone定义。czyaml包含Meta、Guest、Resource三部分，其中Meta包含一些元数据，用以区分不同的Control Zone。Guest部分则用于声明运行环境，包括使用的系统、调度器及根文件系统。Resource部分用于声明隔离的资源，包括常见的CPU、Memory以及Intel RDT子系统中的LLC和内存带宽。
    \item \textbf{czmanager}：Control Zone管理。czmanager负责Control Zone的实际管理， 包括创建、查看、启动、暂停、更新以及清除等完善的生命周期管理。过程中czmanager主要负责维护Control Zone的状态，并协同底层虚拟机监视器实现最终的虚拟机管理。而在可观测性上，czmanager利用了虚拟机各层次的信息生成监控配置，并与可观测性基础设施协作以实现Control Zone的持续监控。资源管理上，czmanager主要与虚拟机监视器、Linux Resctrl及Cgroup子系统交互，根据czyaml中的定义实现Control Zone的资源隔离。
    \item \textbf{czdaemon}：Control Zone守护程序。czdaemon运行在每个Control Zone之中，在启动阶段主要用来信息获取与状态探测。而在启动完成之后，作为Control Zone内外沟通的桥梁，对外与czmanager交互，以接收命令，对内则直接与容器运行时交互，实现镜像及容器的管理。
    \item \textbf{czctrl}：用户命令行工具。czctrl是所有请求的入口，能够解析用户输入的命令并验证czyaml配置，随后再与czmanager交互以达成用户管理Control Zone和任务的目的。
    \item \textbf{镜像存储服务}：容器及其他静态资源管理。应用与Control Tower任务调度策略都以OCI容器镜像的形式保存在镜像存储服务中，并通过容器的形式运行，同时为方便其他静态资源的管理，预编译内核及根文件系统也保存在精简容器镜像的中交给镜像存储服务管理。
\end{itemize}

\subsection{Control Zone流程}

% 要解决的问题，以及解决的问题的思路

% Control Zone Yaml
% Control Zone关键流程的执行过程
% - start
% - stop 
% - update
% - remove
% Control Zone容器的管理流程
% - add
% - delete
% Control Zone调度的流程
% - czctrl的资源限制
% - chsd的策略控制
% - sched ext的策略控制

Control Zone Yaml提供了丰富的配置选项，允许用户自定义沙箱的基本配置，并提供丰富的资源隔离声明。

\begin{itemize}
    \item \textbf{基础配置}：Control Zone基础配置如表~\ref{tab:cz_meta_config}所示，首先，在Guest环境上，Control Zone提供了Response、Throughput两种基本内核，用户可根据需要进行选择。而为加快启动速度，Control Zone默认不使用initramfs，并采用基于Alpine的轻量化rootfs。轻量化rootfs中仅包含基础的软件运行环境，用户也可以根据需要进行修改。在应用管理上，Control Zone使用类似Pod Yaml的配置文件来描述混部任务的部署需求，其中Control Tower调度器与常规应用一样包含在配置文件中。

\begin{table}[H]
    \bicaption{\quad Control Zone Meta 配置}{\quad Control Zone Meta Config}% caption
    \label{tab:cz_meta_config}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.25}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        %\multicolumn{num_of_cols_to_merge}{alignment}{contents} \\
        %\cline{i-j}% partial hline from column i to column j
        配置 & 说明\\
        \hline
        name & Control Zone名称 \\
        workdir & Control Zone工作目录，存放日志及其他配置 \\
        share\_folder（可选） & 额外共享给Control Zone的目录 \\
        label & 标签，数个key-value对 \\
        vrun & 虚拟机监视器，可选CloudHypervisor、Qemu \\
        initramfs（可选） & 初始化内存文件系统，默认情况下不使用 \\
        rootfs（可选） & Control Zone使用的根文件系统，从镜像存储拉取\\
        kcmdline（可选） & 内核的运行命令 \\
        pods（可选） & Pod 配置 \\
        \hline
    \end{tabular}
\end{table}

    \item \textbf{资源配置}：KVM虚拟机是一种特殊的进程，Control Zone在创建虚拟机的过程中，会为vCPU及emulator线程创建Cgroup与Resctrl Monitor Group来方便进行资源管理。具体的资源配置选项如表~\ref{tab:cz_cgroup_config}所示。首先，可基于Cgroup配置vCPU线程的相关资源，如CPU亲和性与CPU时间片配置。其次，也可通过Resctrl子系统为整个虚拟机线程组配置LLC掩码，来进行Cache资源的隔离。

\begin{table}[H]
    \bicaption{\quad Control Zone Resource 配置}{\quad Control Zone Resource Config}% caption
    \label{tab:cz_cgroup_config}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{30pt}% column separation
    \renewcommand{\arraystretch}{1.25}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        %\multicolumn{num_of_cols_to_merge}{alignment}{contents} \\
        %\cline{i-j}% partial hline from column i to column j
        配置 & 说明\\
        \hline
        cpu.max & 最大CPU使用限制 \\
        cpu.max.burst & 最大突发CPU使用限制 \\
        cpuset.cpus & CPU亲和性 \\
        cpuset.mems & 内存节点亲和性 \\
        llc mask& 可用LLC掩码 \\
        \hline
    \end{tabular}
\end{table}

    \item \textbf{Hypervisor配置}：虚拟机硬件通常由Hypervisor模拟，其中如virtio设备等在模拟设备后端驱动上提供了丰富的配置选项。通过Hypervisor提供的调控接口，可以进一步在设备上进行资源隔离的配置。具体配置如表~\ref{tab:cz_hv_config}所示。首先，对于CPU资源，可配置虚拟机所能使用的CPU feature。对于virtio网络设备和块设备，则可在读写速度上进行配置。

\begin{table}[H]
    \bicaption{\quad Control Zone Hypervisor 配置}{\quad Control Zone Hypervisor Config}% caption
    \label{tab:cz_hv_config}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{30pt}% column separation
    \renewcommand{\arraystretch}{1.25}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        %\multicolumn{num_of_cols_to_merge}{alignment}{contents} \\
        %\cline{i-j}% partial hline from column i to column j
        配置 & 说明\\
        \hline
        cpu features& vCPU可用的特性\\
        bw\_size & 设备带宽大小（byte/s）\\
        bw\_one\_time\_burst & 设备突发带宽大小（byte/s）\\
        bw\_refill\_time & 设备带宽恢复时间（ms）\\
        ops\_size & 设备操作速度（op/s）\\
        ops\_one\_time\_burst & 设备突发操作速度（op/s）\\
        ops\_refill\_time & 设备操作速度恢复时间（ms）\\
        \hline
    \end{tabular}
\end{table}

\end{itemize}

调度动态可定制沙箱提供了create、start、stop、remove、update五种操作来管理Control Zone的生命周期。Control Zone的状态变化如图~\ref{fig:cz_state}所示，其中sync过程由czdaemon完成，并同步给czmanager。对于不能直接达到的状态，czmanager会试图多次切换状态以满足目标。对于无法达到的状态，czmanager会提示操作非法，并终止正在进行的操作。update操作并未在图中，其过程由多个已有的其他操作组成。取决于更新的内容，update具体的操作也有所不同，如对内核的修改将使得Control Zone重新启动，而仅修改CPU时间片大小则不会影响Control Zone的运行状态。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{cz_state}
    \bicaption{\quad Control Zone状态迁移}{\quad State of Control Zone}
    \label{fig:cz_state}
\end{figure}

Control Zone的创建流程如图~\ref{fig:cz_create}所示。过程中首先进行配置的合法性监测，创建过程中的检测主要判断资源是否重复分配，如对于cpuset，czmanager会检查全局的cpu mask来判断cpuset的设置是否合法。随后进行工作目录的创建，用来单独保存每个Control Zone的关键数据，如根文件系统等。创建过程仅为虚拟机的启动做好准备，而并不会启动虚拟机，相当于为虚拟机的启动预留了资源。

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.42\textwidth}
        \includegraphics[width=\textwidth]{cz_create}
        \caption{\quad Control Zone创建流程}
        \label{fig:cz_create}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.56\textwidth}
        \includegraphics[width=\linewidth]{cz_start}
        \caption{\quad Control Zone启动流程}
        \label{fig:cz_start}
    \end{subfigure}
\bicaption{\quad Control Zone创建与启动流程}{\quad Control Zone create and start process}
\label{fig:cz_create_start}
\end{figure}

Control Zone的启动流程如图~\ref{fig:cz_start}所示。过程中首先进行配置的合法性监测，如判断状态迁移是否合法、验证资源是否重复分配。对于一个已经创建的Control Zone，其预留的资源并不是严格进行保护的，因此在启动时其资源可能已经被占用，此时需要涉及重新更新Control Zone的资源配置。而在一切准备就绪以后，czmanager会按照配置要求，调用目标虚拟机监视器来启动虚拟机。而在虚拟机启动完毕之后，czdaemon会检测是否有已经提交的任务，并依次在后台进行执行，随后通知czmanager虚拟机状态的变化。czmanager在收到信号之后，Control Zone的启动过程就完成，而随后czmanager会根据配置来选择为Control Zone同步观测配置。

Control Zone的停止过程如图~\ref{fig:cz_stop}所示。考虑停止之后存在重新启动的可能，因此沙箱采用了较为保守的关闭策略。关闭过程中需要czmanager与czdaemon协同合作。在验证配置之后，czmanager首先会通知czdaemon进行关闭处理。而czdaemon在接收到关闭信号之后，会对当前系统的状态进行保存，包含必要的信息、混部应用状态等，随后终止混部应用的运行并通知czmanager。收到通知后czmanager才会调用执行器关闭虚拟机，并在必要时通知可观测性基础停止监测。Control Zone在停止之后仍会保留部分资源分配信息，便于后续重新启动。

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.46\textwidth}
        \includegraphics[width=\textwidth]{cz_stop}
        \caption{\quad Control Zone关闭流程}
        \label{fig:cz_stop}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.53\textwidth}
        \includegraphics[width=\textwidth]{cz_remove}
        \caption{\quad Control Zone删除流程}
        \label{fig:cz_remove}
    \end{subfigure}
\bicaption{\quad Control Zone关闭与删除流程}{\quad Control Zone stop and delete process}
\label{fig:cz_create_start}
\end{figure}

Control Zone的删除过程如图~\ref{fig:cz_remove}所示。通常只有已经停止的Control Zone能够被删除。为简化操作，当Control Zone为其他状态时，此时进行删除操作时会首先将Control Zone的状态转化为停止状态，再进行删除操作。Control Zone的除了工作目录的销毁外，还会回收已经分配的资源。

% TODO: 描述CT调度器切换的过程

Control Zone的更新过程如图~\ref{fig:cz_update}所示。Control Zone Yaml中的绝大部分字段都允许被更新。部分配置的更新在Control Zone运行中完成，如修改cgroup或resctrl等字段中的内容。czmanager发现这部分字段修改时，会重新修改资源隔离配置，并调用各个资源管理接口来进行实施。而部分字段则会涉及到Control Zone的重新启动，如对Guest中的内核、根文件系统等字段进行修改。czmanager检测到这些字段发生修改后，首先会关闭虚拟机，随后在工作目录中更新配置所要求的内容，最后再启动虚拟机。通常更新完毕后，由于虚拟机进程的变化，可观测配置有可能过时，因此czmanager还会同步配置给可观测性基础设施。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{cz_update}
    \bicaption{\quad Control Zone更新流程}{\quad Control Zone update process}
    \label{fig:cz_update}
\end{figure}

\subsection{Control Zone开销优化}

% 隔离性实现
% 内核裁切
% hypervisor选择
% 系统功能要求
% 镜像共享

Control Zone中使用虚拟机作为沙箱底座，主要出于隔离性与安全性两个因素的考虑。首先，Control Zone需要一个较强的隔离环境，引入虚拟化一方面增强了隔离效果，同时也能够基于Hypervisor来提供更多的资源限制手段。其次，Control Zone中基于调度子系统来协调多任务的执行，使用虚拟机一方面能够提供场景上的限制，如有限的硬件资源、有限的竞争应用等。最后，修改任务的调度信息是较为风险的行为，设置不当有可能引发整个系统的性能劣化，而利用虚拟机能够防止这种风险的扩散。

虚拟机的引入会带来额外的开销，主要体现在虚拟机监视器与系统环境两个层次。一方面，虚拟机监视器需要准备一个完整的虚拟机，而对各个模拟设备进行初始化及配置的过程会产生额外的开。同时在虚拟机运行过程中，虚拟机监视器在需要对设备进行模拟，模拟过程中也会产生额外的开销。另一方面，容器中的应用运行之前，还需要经过经过作操作系统、软件环境以及容器运行时三个阶段的运行环境初始化，每个阶段都会产生额外的开销。

沙箱实现中主要从两个方面围绕开销进行优化。首先，在虚拟机监视器的选择上，沙箱使用CloudHypervisor作为默认的虚拟机监视器。CloudHypervisor与Firecracker类似，都是基于Rust-VMM套件构建的轻量级虚拟机监视器。相比于Firecracker，CloudHypervisor更侧重云场景的实际需求\citep{agache2020firecracker}，在保证轻量的同时，提供更强的性能与更实用的功能，如额外支持了PCI设备模拟以及PCI设备直通。其次，在系统环境上，沙箱实现时围绕三个阶段进行优化。对于操作系统，沙箱实现时参考了Firecracker Kernel配置，并根据需要增加了对PCI、容器、BPF子系统以及Sched Ext调度类的支持。随后，对于启动过程， 沙箱使能了Linux的PVH（半虚拟化）配置，使得不必经过BIOS就能够直接引导系统。同时，由于Control Zone系统环境足够简单，因此不需要initramfs阶段的引导过程而直接挂载根文件系统进入init初始化过程。对于根文件系统，沙箱使用Alpine\citep{alpine}作为基础镜像。Alpine是一个轻量级Linux发行版，使用Busybox与Musl。其中Busybox是一系列Linux基础工具的集合，同时Busybox代码专注于基础功能并高度简化，因此只会占用很小的存储空间。Musl是一个轻量级的C标准库，在设计时就专注于提供最基本的C标准函数与特性，因此占用空间非常小。同时，Musl优化了常见函数的实现，在部分场景下有更好的性能表现。对于容器运行时，沙箱选择了crun\citep{crun}作为Control Zone中的容器运行时。crun使用C语言开发，相较于使用Go语言开发的runc，crun在启动容器上的开销降低了49.4\%，同时占用的内存也更少。

为满足多样的使用需求，沙箱也兼容了对Libvirt支持。Libvirt并不是一个虚拟机监视器，而是针对多种虚拟化技术的抽象层，提供了更标准的API来对虚拟机进行管理。通过兼容Libvirt，沙箱能够获取更多的特性，尤其在可观测性上，沙箱能够借助Libvirt提供的丰富监控机制，从而更方便地为可观测性基础设施提供监测数据。

% \subsection{资源隔离技术}
% - cgroup
% - resctrl / intel RDT
% - hpv virt device

\section{实验设计与分析}

\subsection{实验环境}

实验环境由两台服务器构成，服务器硬件信息如表~\ref{tab:exp_env}所示。在CPU资源上，每台服务器上包含有两个Socket，单台总计80个物理核心，划分为4个Numa Node。同时，CPU均开启超线程，并使能Intel RDT。在网络资源上，服务网卡支持SRIOV技术，能为有网络性能需求的虚拟机提供硬件直通。

\begin{table}[H]
    \bicaption{\quad 服务器硬件参数}{\quad Server Hardware Information}% caption
    \label{tab:exp_env}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.25}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        硬件资源 & 硬件信息 \\
        \hline
        CPU & Intel Xeon Gold 6148 (40 cores) * 2 \\
        Processor Core Frequency & 2.4GHz，Turbo 3.7 GHz \\
        L1 Caches & 32KB,  8-way set associative, split D/I \\
        L2 Caches & 1024KB, 16-way set associative \\
        L3 Caches & 28160KB, 11-way set associative \\
        Main Memory & 32GB * 8, 2666MHz DDR4 \\
        NIC & Intel Corporation Ethernet Connection X722 for 10GbE SFP+(10Gbit) \\
        \hline
    \end{tabular}
\end{table}

每台服务器的系统软件环境如表~\ref{tab:system_env}所示。在操作系统上，实验中选择使用较常见的Ubuntu22.04 LTS。Ubuntu同时也是Sched Ext优先支持的发行版，能较方便地通过包管理工具安装预编译的Sched Ext内核及相关工具。在虚拟机监视器上，Qemu采用Ubuntu22.04所支持的稳定版，CloudHyeprvirsor则采用v38.0-150发布版。

\begin{table}[H]
    \bicaption{\quad 服务器系统环境}{\quad Server System Information}% caption
    \label{tab:system_env}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{30pt}% column separation
    \renewcommand{\arraystretch}{1.25}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        软件类型 & 软件信息 \\
        \hline
        系统 & Ubuntu 22.04.3 LTS  \\
        内核 & 5.15.0-79-generic \\
        虚拟机监视器 & cloud-hypervisor v38.0-150 \\
                   & QEMU emulator version 6.2.0 \\
        其他        & libvirtd 8.0.0 \\
        \hline
    \end{tabular}
\end{table}

除系统软件之外，每台服务器还按照需要部署了其他关键服务，包含第3章中设计的可观测性基础设施。Observer节点上部署的了Prometheus与Grafana，用于进行数据采集与离线分析。其次，Observer上还额外部署了Harbor来对外提供镜像存储服务。Observed上部署了第3章中设计的一系列Exporter及Control Zone各组件。实验中所有的组件都以容器的形式运行，选择较为轻量的Podman作为服务器中的容器运行时。Podman相较Docker更加轻量，不存在Docker、Containerd等后台驻留服务，提供较纯净的环境。而为避免可观测性基础设施对其他应用的影响，各组件都配置了CPU亲和性并限制在固定的CPU、NUMA上执行。

\subsection{启动开销实验}

Control Zone的启动开销计算从虚拟机监视器开始到系统引导至init过程的时间，虚拟机使用1 CPU与512 MB内存的基础配置。在虚拟机监视器上，选择CloudHyperviosr与Qemu进行对比。在精简内核上，选择Alpine Virt内核、Control Zone内核，以及CloudHyeprvirsor、Firecracker的默认内核。其中Alpine Virt内核为社区提供给云厂商的标准虚拟机内核，启动了大部分Guest优化功能，但同时也保留了对于众多设备的支持。而以轻量为目标的CloudHyeprvirsor、Firecracker也各自提供了默认的精简内核，相较于Alpine Virt内核，去除了大量无意义的驱动，几乎只支持virtio设备。而CloudHypervisor默认内核还额外使能了PCI配置，以便于使用SRIOV设备。实验中虚拟机均使用virtio pci设备，因此为使得实验结果具备可比较性，使能了Firecracker默认内核的PCI配置。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\textwidth]{avg_boot_time}
    \bicaption{\quad 平均启动时间比较}{\quad Comparison of average boot times}
    \label{fig:avg_boot_time}
\end{figure}

实验结果如图~\ref{fig:avg_boot_time}所示，Control Zone内核的平均启动开销相较于Alpine Virt内核最高降低了88.8\%。对比不同的虚拟机监视器的数据发现，优化效果的绝大部分来自于对内核的裁切。Control Zone内核仅支持运行容器、BPF子系统与Sched Ext调度类的最小功能，因此在启动时省去了大量非必要的工作，从而能够做到足够快速。同时，即便对于相同的Alpine Virt内核，使用CloudHypervisor相较于Qemu降低28.9\%的启动时间。观察两者的启动日志能够发现，虚拟机启动时间的差异主要来自于模拟设备的初始化上。CloudHypervisor仅针对云场景，因此相较于Qemu去除了大量的无关设备模拟。更少的模拟设备一方面减少了虚拟机监视器的启动时间，另一方面Guest内核在设备探测与初始化上花费的时间也更少。尤其在PCI子系统的初始化上，相较于Qemu，CloudHypervisor在PCI初始化上的平均时间减少了83.2\%。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{boot_time_cdf}
    \bicaption{\quad 精简内核的启动时间比较}{\quad Comparison of Kernel Boot Time Optimization} 
    \label{fig:boot_time_cdf}
\end{figure}

而对于精简内核，由于支持的PCI设备更少，因此在模拟设备初始化时间上的优化效果就并不明显。但与其余精简内核相比，Control Zone内核也存在一定优势。如图~\ref{fig:boot_time_cdf}所示，使用Qemu时，Control Zone内核相较于CloudHypervisor默认内核在启动时间上减少了20.6\%。对比两者配置差异发现，CloudHypervisor所提供的精简内核虽然去掉了大部的驱动支持，但仍然保留了如虚拟化子系统在内的配置，因此存在额外的开销。Control Zone内核由于只需要支持容器运行环境，因此能够取得更快的启动速度。但是相较于Firecracker默认内核，Control Zone即便在CloudHypervisor下也仅能达到Firecracker在Qemu下的启动时间。比较两者的配置能够发现，Firecracker内核在功能裁切上更加激进，不支持容器运行环境与BPF子系统。然而在Control Zone内核中，这些功能则是必要的。在具体使用场景中，Firecracker注重安全容器的需求，虚拟机的生命周期与运行在其中的应用绑定。但在Control Zone的设计中，Control Zone并不完全与混部应用绑定，而是一种可复用的运行环境。Control Zone在混部应用部署时启动，而在应用结束后仍然会保留一段时间，并提供给需要类似隔离环境的其他混部应用使用。因此在启动时间上花费更多的时间在Control Zone的设计中是可以接受的。

\subsection{性能开销实验}

实验中选择典型应用分析中的6种应用进行性能测试，分析Control Zone上实际应用的性能。在内核性能上，选择与CloudHypervisor默认Linux内核进行比较，并同时运行在Control Zone沙箱上。而在沙箱性能上，选择与在Host上以容器的形式部署的应用进行比较。

性能开销实验结果如图~\ref{fig:perf_app}所示，总体来看，Control Zone在内核性能上优于CloudHypervisor默认的Linux内核，而在沙箱性能上，Control Zone在一些应用上能够实现优于直接在Host上部署的性能。

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_redis}
        \caption{\quad Redis请求延迟}
        \label{fig:perf_redis}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_memcached}
        \caption{\quad Memcached请求延迟}
        \label{fig:perf_memcached}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_mysql}
        \caption{\quad MySQL每秒事务数量}
        \label{fig:perf_mysql}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_nginx}
        \caption{\quad Nginx请求延迟}
        \label{fig:perf_nginx}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_ffmpeg}
        \caption{\quad FFFmpeg 每秒处理帧数量}
        \label{fig:perf_ffmpeg}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{perf_graph500}
        \caption{\quad Graph500 每分钟执行数量}
        \label{fig:perf_graph500}
    \end{subfigure}
\bicaption{\quad 应用性能比较}{\quad Application performance comparison}
\label{fig:perf_app}
\end{figure}

Control Zone内核仅以提供隔离的内核环境为目标，在此目标上进行的内核配置裁切能够更加激进。相较于CloudHypervisor默认内核，Control Zone内核在同样仅支持Virtio设备的同时，裁切了如Netfilter等在沙箱中不必的内核功能，从而进一步减少内核中如网络处理等关键路径的长度。因此网络应用延迟上，与同样运行在虚拟机中的CloudHypervisor内核相比，Control Zone实现了99分位尾延迟降低最高15.7\%的效果。同时，与直接运行在Host上相比，Control Zone即便引入了虚拟化开销，也能够实现99分尾延迟降低最高38.5\%的效果。

但对于一些逻辑复杂的应用，如MySQL，Control Zone存在一定的性能瓶颈。造成这一问题的核心原因是虚拟设备的性能限制。而在当前虚拟化技术中，通过SRIOV等硬件直通手段可以有效地处理这一问题，因此Control Zone内核中保留了PCI总线配置以便驱动直通的硬件。

\subsection{性能保障实验}

性能保障实验在4 CPU、1024MB内存的Control Zone中展开，选择Qemu组合CloudHypervisor默认内核作为运行环境的对比。Control Zone中的混部方案为Memcached、stress\_ng CPU干扰应用与Control Tower调度策略，Qemu的混部方案为Memcached、stress\_ng CPU干扰。实验方式为分别在两个混部方案中运行一段时间相同的Memacached负载，并从可观测系统中截取对应时间段的指标数据。

时序数据如图~\ref{fig:cpu_series_memcached}所示，包含虚拟机总体的CPU使用率、混部应用各自的CPU使用率以及Memcached的99分位尾延迟，其中红色虚线部分表示stress\_ng CPU负载启动的时间点。在干扰负载启动之前的时段，Memcached在Control Zone中的性能表现无明显差异。而在干扰负载启动之后的时段，Memcached在Control Zone中运行时的延迟需求得到了有效的保障，并实现99分尾延迟降低最高63.8\%的效果。

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{cpu_series_memcached_ct}
        \caption{\quad Control Zone混部性能}
        \label{fig:cpu_series_memcached_ct}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{cpu_series_memcached_eevdf}
        \caption{\quad Qemu + CloudHV Kernel混部性能}
        \label{fig:cpu_series_memcached_eevdf}
    \end{subfigure}
    \bicaption{\quad 混部场景下Memcached性能保障}{\quad Memcached performance protection in co-location scenario}
    \label{fig:cpu_series_memcached}
\end{figure}

而从CPU资源分配的角度上来看，Memcached在Control Zone中运行时能被更优先地分配CPU资源，从而能够更好地进行请求处理，实现延迟的降低。与此同时，虚拟机总体CPU使用率却没有明显下降，这得益于Control Tower调度策略对于高优先应用CPU资源使用的感知，并通过合理的CPU分配实现高优先应用的性能保障。

% 补充实验
% - 总体性能指标
% - 混部场景变化实验
% - 同时运行实验

\section{本章小结}

本章首先介绍了运行时调度可变的沙箱Control Zone的基本概念，以及其对数据中心中单节点混部场景的处理方式，即结合外侧虚拟机资源隔离与内部Control Tower任务调度策略。

随后介绍了沙箱中的czctrl、czmanager、czdaemon等组件及其主要功能，并详细阐述了Contorl Zone的隔离能力以及Control Zone生命周期管理中各个组件的协作流程。

由于Control Zone中的Control Tower任务调度策略也以容器的形式运行，因此能够和普通任务一样进行管理。因此在任务部署上，Control Zone允许将混部任务与调度策略共同部署，通过定制化调度来解决混部下的性能劣化问题。

然后介绍了Control Zone在实现中为解决引入虚拟化带来的开销做进行的工作，包括对内核的裁切以及轻量化Hypervisor的选择。

实验设计中，在沙箱启动开销上，比较了Control Zone虚拟机的启动时间，通过在Hypervisor、Guest OS上的裁剪优化， Control Zone能够达到与领先轻量级虚拟化相近的水平。而在性能开销上，选择6种应用进行性能测试，Control Zone沙箱在多数应用上都取得了更好的性能，同时依托内核上的裁切，能够弥补虚拟化所带来的开销，并达到应用性能优于在Host上直接部署的效果。

而在混部性能保障上，Control Zone部署混部应用能够利用Contorl Tower调度策略的灵活性与调控能力，通过更符合混部场景的CPU资源分配策略，能够实现高优先应用99分尾延迟降低最高63.8\%的效果。