\chapter{引言}\label{chap:introduction}

\section{本文的研究背景与意义}

% 问题 -> 
% - 数据中心规模不断扩大
% - 提升利用率的重要性
% 解决方式 -> 混部技术
% - LS 和 BE 应用天然具备混部
% - 通过混部的确解决了问题
% 局限 -> QOS
% 本质 -> 混部共享资源的竞争
% - CPU\Cache\Memory\IO\Net
% - AVX
% 研究现状
% - 劣化监测
% - 调度
% 本研究

云计算为用户提供了使用计算资源的便捷方式，同时虚拟化技术让云计算服务具备了弹性、安全等特征，能够大大减轻服务上云的管理负担。而随着Podman、Docker等容器技术的发展，服务上云的门槛也被极大降低，同时，随K8s、OpenShift等容器编排技术发展及DevOps概念的推广，使得企业与普通用户都越来越倾向于服务上云。不断扩张的需求催生了巨大的云计算市场，这也促使着云厂商不断扩大着数据中心的规模，据中国信息通信研究院的中国算力发展指数白皮书（2023年）显示，2022年国内基础算力规模达到180EFlops，位居全球第二，同时在用数据中心机架规模超过650万个标准机架\citep{chinaict2023}。

庞大的数据中心带来了巨大的管理治理挑战。微软Azure是世界最大的云厂商之一，其调研内部数据发现在数据中心中，每提升1\%的利用率，能够每年节省近1亿美元\citep{hadary2020protean}。因此，如何高效地利用数据中心海量的计算资源，提高整体资源利用率是云厂商重点的关注的核心问题。

超卖是云厂商提升数据中心资源利用率的一种方式，主要涉及到计算资源与存储资源。CPU超卖是最常见的计算资源超卖方式，虚拟化技术让同一个物理CPU上能够运行多个vCPU，存储池化技术则使得云厂商能够出售用户比实际存储还要多的存储资源。随虚拟化技术的不断发展，一方面，虚拟化开销在不断降低，另一方面，虚拟化层次也在不断提升。更高的虚拟化层次模糊了用户的计算需求，为云厂商进行超卖提提供了更多的空间。然而越来越极限的超卖比无疑会造成更激烈的资源竞争，从而导致严重的用户服务质量（QoS）下降，这对云厂商而言意味用户数量的流失。

考虑到服务器上越来越丰富的计算资源能够支持更多的应用同时运行，混部技术逐渐成为当前云厂商提升数据中心利用率的主要方式。混部同样能够将更多的任务调度到同一个服务器上，但不同于资源超卖，混部考虑了数据中心所部署应用的互补特征。当前数据中心应用依据用户对延迟的敏感度，可划分为延迟敏感性（LC）与尽力交付型（BE），前者通常为交互型应用，如在线购物等，用户对于延迟要求较高，后者则通常为离线应用，如大数据处理等。以阿里云为例，通过混部分别将集群的平均CPU利用率和内存资源利用率提升到了38.2\%和88.2\%\citep{guo2019limits}。

然而混部并没有解决资源竞争导致用户QoS劣化的问题。一方面，服务器整体处理能力有限，无论资源超卖还是混部，都试图向单一服务器上引入更多的任务，来挖掘资源利用的极限，而过多的任务就会积压导致排队，从而产生较大的延迟。另一方面，服务器局部的硬件资源也容易成为瓶颈，常见混部策略试图让延迟敏感度不同的应用同时运行，然而数据中心软件环境较为复杂，不同应用也有不同的资源敏感度，同时运行的应用就容易因某一处共享的资源上的激烈竞争导致严重的性能劣化。

竞争本质是共享资源的供小于求，因此分析竞争问题首先需要了解服务器上的共享资源。调度域(Scheduler Domains)\citep{schedulerdomains}在Linux 2.6中首次引入，用来协助在当时逐渐流行的多核处理器上的调度，而随着CPU设计与制造技术的不断进步，CPU的拓扑结构也越来越复杂，当前如超线程技术(Hyperthreading)、非同一内存访问架构（NUMA）、大小核心架构等CPU架构上的新特性带给Linux调度器设计上的巨大的挑战，如图~\ref{fig:scheduling_domain}所示，调度域作为应对这一挑战的关键抽象层，其提供了一种机制，使得Linux内核能够更好地理解CPU之间的关系，从而更智能地进行任务调度。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{scheduling_domain}
    \bicaption{\quad 调度域层级}{\quad scheduling domain hierachies}
    \label{fig:scheduling_domain}
\end{figure}

调度域充分反映了围绕CPU的共享资源信息信息。如表~\ref{tab:resourcesharing}所示，一个逻辑核通常是最底层的调度域，在这层调度域中，任务通过分时复用共享CPU资源，所有任务组织在一个或数个任务队列中，某一时刻仅有一个任务在运行，彼此几乎不存在影响。超线程组是更高一层的调度域，超线程技术由Intel公司提出，并最早于2002年引入市场，如图~\ref{fig:cpu_topology}所示，其通过增加CPU中的部分单元，使得能够在一个物理核心上虚拟出两个甚至多个逻辑核心，这些逻辑核心有自己的寄存器组与中断控制器，但彼此共享了执行单元、Cache和总线，这也意味着在这层调度域中运行的任务，彼此在这些资源上会产生竞争。现代采用NUMA架构的服务器中还有更高一层的NUMA调度域，NUMA（非一致存储器访问）架构中允许有多个CPU模块，每个CPU模块可以包含多个CPU，这些CPU拥有自己的本地内存与IO接口，彼此之间的通信交互通过互联模块完成，在这个调度域中，任务共享了相同的内存总线与LLC，同时在IO上也会彼此竞争。

\begin{table}
    \bicaption{\quad 调度域与共享资源}{\quad scheduler domains and resource sharing}% caption
    \label{tab:resourcesharing}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.5}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        %\multicolumn{num_of_cols_to_merge}{alignment}{contents} \\
        %\cline{i-j}% partial hline from column i to column j
        调度域 & 共享资源\\
        \hline
        Core & 几乎隔离\\
        HyperThread & 执行单元、缓存、总线\\
        NUMA & 末级缓存、内存带宽、IO\\
        \hline
    \end{tabular}
\end{table}

混部场景下QoS保障技术相关研究通常从三个方向展开：

1）其一是利用可观测性技术来进行应用性能画像与劣化监测。一方面是云厂商通过增强可观测性基础设施，来提升对数据中心持续监控与性能预警能力，2011年，Google公开了其数据中心混部集群监控数据集，国内阿里也在2017年公开了一部分混部集群的监控数据集\citep{guo2019limits}，这些来自实际生产环境的脱敏数据集，极大促进了相关混部研究的发展。另一方面随云原生时代到来，可观测性粒度能细化到单个应用甚至函数，而通过对应用进行全面深入地观测，就能够利用丰富的指标数据来进行细致地画像分析，从而挖掘出更多的混部机会，制定更优的混部策略。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{cpu_topology}
    \bicaption{\quad CPU片上共享资源 }{\quad CPU on-chip shared resources}
    \label{fig:cpu_topology}
\end{figure}

2）其二是围绕资源划分的混部研究。资源划分即通过软硬件等手段，强化混部场景下竞争应用在资源上的隔离性，防止因关键资源的竞争所引发的性能劣化。在软件上，可以通过Cgroup等手段配置任务的CPU亲和性，将彼此竞争的应用放置到不同的调度域中，也可以通过 traffic control技术\citep{hubert2002linux}协调任务对于网络资源的使用。在硬件上，可以采用Intel RDT技术\citep{guide2011intel}，来对同一NUMA调度域中，共享末级缓存与内存带宽的任务进行资源协调，避免“吵闹邻居”问题\citep{xu2018dcat, maricq2018taming, rzadca2020autopilot, kwon2020dc}。

3）其三则尝试通过任务调度来解决干扰问题。基于资源划分的混部技术通常受限于软硬件的隔离能力，如Intel MBA对内存的调控就存在一定的延时\citep{herdrich2016cache}，在瞬时流量激增的场景中就难以及时响应任务的资源需求。任务调度通常以微秒级调度为主，并以CPU资源为主要分配的资源。事实上，资源的分配一般都以CPU分配为起点，只有当任务分配到CPU执行时，才会有后续其他资源的分配或使用。因此基于任务调度的研究一方面采用集中式队列来更好地进行全局调度决策，另一方面通过实施微秒级调度，让任务能够在短时间内获取CPU资源，从而减少延迟问题。

基于上述研究，本文首先设计了一套细粒度的可观测性系统，监测应用的性能指标并在其获取系统关键资源的路径上进行探测，完成对典型应用的画像分析。然后，本文提出了 Control Zone, 一种面向混部场景的运行时调度可变的沙箱机制实现，如图~\ref{fig:controlzone}所示，系统中首先按照CPU以及其他资源的拓扑，将服务器资源切割成数个隔离域，随后在隔离域中部署混部方案。而考虑到数据中心的混部方案随应用数量和画像的程度而增加，同时无论是围绕资源分配还是任务调度的混部手段，都无法保障能在每个场景下有效，Control Zone允许在不同隔离域中实施不同的内核调度策略，同时考虑到应用在不同负载下性能表现的不同，允许运行时对内核调度策略进行动态修改来适应混部策略的变化。而在隔离域外，则结合软硬件手段，来对影响任务性能的关键软硬件资源进行隔离保护。最后则针对不同的混部方案，设计一系列调度策略，提供常见混部场景的解决方案。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{controlzone}
    \bicaption{\quad Control Zone架构}{\quad Control Zone Architectural}
    \label{fig:controlzone}
\end{figure}

\section{国内外相关研究}

% 可观测性技术用来进行应用画像与劣化监测
% - 谁和谁能够混部
%   - 人为优先级: 延迟(LC/BE)
%   - 资源使用倾向/敏感度
% - 目标应用是否出现性能劣化/资源极限
% 调度技术的划分方式:
% - 实质: 
%   - CPU数量远小于任务数量时, 分时复用是常态，调度主要面向任务切换
%   - CPU数量足够时，任务可以并行，此时资源(异构CPU\Cache\Memory\IO\Net)共享是常态，因此调度主要面向资源划分
% - 任务切换: 修改或定制任务切换的逻辑，通过分时复用来实现共享资源的假象
%   - 实质是创建时间隔离域，来规避竞争
%   - 切换粒度与调度效果强相关, 能否及时响应任务的调度需求是设计的目标
% - 资源划分: 对任务使用的资源进行限制
%    - 创建资源隔离域，来规避竞争
%   - 任务仍在运行|任务由内核进行调度|不干涉任务调度过程
% 调度策略的划分方式:
% - 任务调度: 集中式、工作窃取、FIFO、CFS、EEVDF
% - 资源划分: 资源拆借

\subsection{数据中心可观测性与劣化监测研究现状}

% 劣化监测
% 分布式追踪(简单提一下)

SLO（Service-level objective）服务级别目标指定了用户所购买云服务功能的期望状态，通常包含服务可用性、带宽等基础指标，也包括每秒请求数量、尾延迟等业务性能指标。云厂商通过与用户协商SLO来定义云产品的质量保证，并在违反SLO时进行补偿。因此如何持续监测云服务质量并及时发现性能劣化时云厂商十分关注的问题。

可观测性技术是实现上述目标的基础设施，能够通过监控、日志记录、跟踪和其他数据收集手段来描述系统的状态，协助理解和诊断系统的行为和性能。大型数据中心中由于应用数量众多、软件环境复杂，因此云厂商更倾向于一些简单易懂的指标，来反映应用的性能，早期Google就使用CPI来作为应用的性能指标\citep{zhang2013cpi2}。CPI(Cycle Per Instruction)本身用于度量微观体系结构下的性能，应用正常运行时，CPI通常在一个小范围内波动，而当应用受到干扰导致运行速度变慢时，CPI的确能够很好地反映性能的劣化。然而在Li YI等人的研究中\citep{yi2020cpi}，CPI在核心频率较低时存在较大的误差，并通过建模分析优化得到RCPI来对误差进行修正。

随AI技术的不断发展，研究者们发现数据中心的监控数据作为时序数据能够很方便地利用现有的AI数据分析技术进行分析，将AI和系统结合的研究也不断展开，而通过时序数据对服务性能劣化进行预测\citep{qiu2020firm, zhou2022aquatope, wang2022deepscaling, gan2021sage, ghafouri2020survey,zheng2020web,wu2019posterior}，也使得提前一步进行SLO保障成为可能。然而AI预测模型由于计算开销大、时间长，在单点调度上很难进行部署。

近年来随云原生可观测技术、DevOps技术的发展，可观测性技术在云服务中占据了越来越重要的地位。当前借助服务容器化以及容器编排技术的发展，云原生可观测性技术发展十分迅速。以指标监控为例，Prometheus监控系统提供了统一的数据采集格式以及灵活的检索系统\citep{brazil2018prometheus}，而其在架构上的灵活性与可扩展性，也使得其能够方便地对大规模集群进行监控。而在服务质量上，2010年，Google提出了分布式追踪系统Dapper\citep{sigelman2010dapper}，通过在rpc中嵌入span载荷，并允许span在rpc中进行传递，来实现对请求分布式处理过程的追踪。OpenTracing和OpenTelemetry等开源项目吸收了Dapper的核心思想并迅速在云原生社区中推广，当前大多数云原生应用都支持了基本的云原生可观测性，使得在集群中能够相对方便地收集云服务的QoS信息。同时，K8s向开发者开放了CNI(Container Network Interface)\citep{k8s-network-plugins}，允许开发者自定义容器网络模型，同时能够结合eBPF、Envoy等云原生网络技术\citep{ebpf,envoyproxy}，能够构筑一套完善Overlay Network系统，实现全链路的网络性能监测。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{k8s_scheduler}
    \bicaption{\quad k8s调度流程}{\quad k8s scheduler}
    \label{fig:k8s_scheduler}
\end{figure}

云原生可观测性地迅猛发展也提供丰富的监测信息，同时K8s所设计的基于标签的调度机制也极具灵活性（图~\ref{fig:k8s_scheduler}），而其为开发者提供了丰富的接口也大大降低了定制调度器的难度，以上这些都使得面向集群的劣化监测技术发展迅猛\citep{xiang2023godel,zhang2022crisp}。FIRM\citep{qiu2020firm}面向K8s集群设计了一种两级的机器学习模型来识别集群中服务性能劣化，并在实验中取得了相当显著劣化监测与调度效果。而同时Di Wu\citep{wu2020data}则提出了一种数据特性感知潜在因素（DCALF）模型来实现高精度的QoS预测，能够依据不同QoS数据的特性来分别的进行预测。

\subsection{基于资源划分的QoS保障研究现状}

% 集群维度: 放置策略
% 单点维度: 细粒度分配

数据中心资源一般能从集群或单节点的角度进行分析。从集群角度审视时，研究的重点在于考虑任务的放置，即集群作业调度。集群中各个节点的资源特征、空闲情况以及标签信息构成了数个资源域，将任务放置到合适节点的过程实际是基于已有的资源隔离，如不同机架上构成的物理机隔离、不同网络段构成的网络隔离，设计一种合适的放置策略，使得被调度的任务能够占用足够的资源，从而减少QoS的劣化。Protean\citep{hadary2020protean}是微软Azure面向虚拟机混部的调度系统，其中首先对于Azure庞大的数据中心按地区、陈列等信息扩展出更多维度的调度域，在采用一种分层决策的调度机制来寻找虚拟机适合放置的位置。合适的放置策略能够保证任务的QoS，另一方面也有利于提升资源的利用率。

从单点角度审视时，研究的重点则考虑的应用之间的差异性。云原生时代应用通常以容器的形式直接进行部署，不同于虚拟机，容器本质上是进程，并由单点上的操作系统直接进行管理，这一方面减少了虚拟化带来的开销，但另一方面也由于去除了Hypervisor层，使得单点上的应用环境更加复杂。因此相关研究重点在于分析应用之间的差异性，通过软硬件手段对资源进行限制，来避免混部任务在关键资源上的竞争，从而实现QoS保障。其中Paragon\citep{delimitrou2013paragon}、Quasar\citep{delimitrou2014quasar}对多种应用建立分类模型，从而能够快速地确认位置应用的负载类型，进而利用类别信息辅助进行调度决策。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{parties_app_dif}
    \bicaption{\quad 不同资源干扰对应用性能的影响（图片引用自文献\citep{chen2019parties}）}{\quad Impact of diferent resource interference on application performance（This picture is cited from the paper\citep{chen2019parties}）}
    \label{fig:parties_app_dif}
\end{figure}

硬件上的资源隔离手段也推动着相关研究的开展。硬件厂商为解决"吵闹邻居"问题，提供了多种硬件隔离手段，如Intel RDT、ADM PQoS\citep{amdpqos}、ARM MPAM\citep{armmpam}等。Heracles\citep{lo2015heracles}则从应用资源敏感度的角度着手，分析不同应用在不同负载下对于多种资源的敏感度，然后依据分析结果，通过软硬件手段，保证应用的敏感资源的供给，从而实现应用的QoS保障。Parties\citep{chen2019parties}分析了更多种类应用的资源敏感度，如图~\ref{fig:parties_app_dif}所示，而在调度上，Parties不同于Heracles，而是在保障QoS的前提下，通过在应用之间拆借资源来提升整体资源利用率。CLITE\citep{patel2020clite}利用贝叶斯优化构建资源划分模型，将多个LC应用与BE应用进行混部，并利用Intel MBA来对内存带宽进行控制，从而保障LC应用的QoS需求。LIBRA\citep{zhang2021libra}则基于一种新的硬件节流机制，来实现内存带宽的动态资源控制，从而自适应应用的QoS需求。

\subsection{基于任务调度的QoS保障研究现状}

% 内核任务调度
% 微秒级调度

考虑到资源划分存在的劣势，基于任务调度的QoS保障研究将视角拉回到CPU资源分配上。相关研究通常围绕任务运行时与调度策略的设计展开。任务运行时需要对任务的上下文切换、中止与恢复进行管理，同时调度间隔也是重要的性能指标，而调度策略通常用来决定不同任务的CPU资源。

Linux内核是应用最广泛的运行时，其调度机制的设计也是许多研究中运行时实现的参考标准。CFS（完全公平调度）\citep{pabla2009completely}是Linux中重要的调度策略，最早于2009年提出，距今已使用超过15年，其最初的设计目标是用于解决交互式应用于非交互式应用的调度问题。CFS的核心是CPU虚拟运行时间的计算与维护，其会为每个进程维护一个时间记账信息，并根据进程地静态优先级，在每个时钟中断时更新进程的记账信息，而在进行调度决策时，选择虚拟运行时间最小的进程运行。CFS本身使用的是一种启发式的策略，但由于其计算简单，且能在多数场景下有效，因此一直是内核中的默认调度算法。然而随着数据中心应用的不断发展，CFS也暴露出越来越多的问题。在典型的LC应用与BE应用的混部场景中，LC应用相对于BE应用拥有更高的有限级，CFS实现的优先级机制能够保证LC应用获得更多的CPU时间片，但无法保证LC应用及时地获得CPU时间片，这是因为在CFS的设计之中，相同任务队列中的任务总是使用相同的时间片大小。而为了解决这一问题，2023年Linux 6.6版本中引入了EEVDF来作为CFS的替换。EEVDF算法\citep{stoica1995earliest}提出于1995年，其会为每个进程维护一个虚拟截止时间，并在每次调度时选择最早截止时间的任务执行，而不同于CFS，EEVDF的优先级设计考虑到了延迟，并引入了latency-nice机制，高latency-nice的任务总是获得长而少的时间片，而低latency-nice的任务总是获得短而多的时间片，因此在调度决策时，低latency-nice的任务会更容易得到调度。如图~\ref{fig:eevdf_scheduling}所示，通过为LC应用设置更低的latency-nice，能够有效地保证LC应用的QoS需求。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{eevdf_scheduling}
    \bicaption{\quad EEVDF延时优先级调度}{\quad EEVDF latency-nice scheduling}
    \label{fig:eevdf_scheduling}
\end{figure}

然而替换为EEVDF仍然无法解决Linux在调度上的许多问题。这些问题通常与底层硬件相关，HT使得相同物理核心上能够运行多个逻辑核心，这种机制提升的CPU资源的利用率，然而在相同HT调度域中的任务，彼此因共享了部分片上资源而导致相互竞争，而为解决这一问题，Elfen\citep{yang2016elfen}设计了一种内核调度机制，其首先对BE任务进行修改，让其能够以微秒级粒度执行探测代码，使得当HT兄弟核上的LC任务运行时，立即释放CPU资源来保证LC任务的执行。AVX指令（高级向量扩展）\citep{guide2011intel} 最初由Intel提出，并从2011开始加入到处理产品中。AVX指令是SIMD技术的一部分，旨在提高处理器浮点运算性能。AVX指令的实现涉及到处理器片上的加速器，使用这些加速器意味着更高的能源开销，而Intel为了防止芯片过热，会主动降低CPU的运行频率，而这就引发了两个问题。首先如果降频发生在任务切换时，由于频率的恢复需要一定的时间，这就使得同属于同一个逻辑核调度域上的前后两个任务会互相影响，其次由于HT共享了同一个物理核，降频也意味着HT siblings也会受到影响。Gottschlag\citep{gottschlag2020avx}发现了这一问题，并设计了一种监测机制，能够发现AVX指令的执行， 并通过优化内核调度机制来对受到影响的任务进行CPU时间补偿。

Linux社区对于涉及核心基础架构的修改十分审慎，EEVDF算法从提出到被内核接受也用了近29年，同时由于修改内核代码十分危险，因此许多对于内核调度策略的优化机制都很难在生产环境中逻辑。而为了加速Linux内核调度机制的迭代速度并降低调度器的设计难度，Google提出了ghOSt\citep{humphries2021ghost}调度框架，该框架包含内核态、用户态以及协议三部分，其中内核部分不断地更新任务的调度信息，并按照既定的协议生成调度事件，用户态部分则消费这些调度事件，并通过系统调用向内核发送调度决策。同时Meta也提出了基于eBPF设计的Sched Ext调度类，允许开发者利用eBPF来对内核调度机制进行扩展。在用户态实现调度程序能够避免了在内核进行开发的诸多问题与限制，同时这种灵活的机制方便了开发者应对不同的混部场景进行针对性的优化。

围绕Linux内核的任务调度还存调度粒度上的问题，当前Linux调度的时间片计算通过时钟中断完成，更细的调度粒度会导致过多的时钟中断，挤兑常规任务的处理事件，造成CPU资源的浪费。而为解决这一问题，许多研究者通过自建任务运行时来绕过内核调度，并实现微秒级粒度的调度\citep{yang2016elfen,ousterhout2019shenango,fried2020caladan,prekas2017zygos}。Caladan\citep{fried2020caladan}在Linux内核之上设计了一套用户态运行时，并关闭内核中的抢占功能来减少内核调度的噪声，同时基于DPDK、SPDK实现了用户态的网络与IO设备驱动来支持应用的正常运行，这些工作一方面使得运行时能够规避用户态与内核态的切换，从而实现更细的调度粒度，另一方面也允许在用户态针对混部场景的特点定制调度策略来保证LC应用的QoS。

\section{论文的研究内容}

本文主要研究混部场景下的单点QoS保障机制，综合以上相关理论研究能够发现：

1）当前数据中心对应用的分类比较简单，而仅以LC与BE两类应用对应用进行分类容易忽略更多的混部机会。其次，当前基于云原生的可观测性系统能够提供应用在性能与QoS上的细致指标，便于进行画像分析与劣化监测。

2）基于资源划分的QoS保障技术存在许多劣势。首先在集群侧，宏观的放置策略很难关注到不同应用的差异性，同时数据中心中包含有大量的RPC应用，这些应用的性能会随负载的变化而变化，并呈现出不同的资源亲和性。其次在单点维度，现有研究的调度过程常都在用户态完成，而决策过程中所依赖的信息、调控手段则依赖操作系统的协助，一方面缺少了来自内核的更丰富的监测信息，另一方面由于调度需要在用户态与内核态多次切换，因此产生的权限墙限制了调度的频率，在延时敏感的场景中，就容易错过调度的机会，导致应用延迟的上升，以及调度不及时所引发的“乒乓效应”。

3）Linux内核社区对调度机制有通用性的要求，因此在设计上相对保守，这就使得内核调度策略通常灵活性较差，而随着内核社区推动EEVDF加入主线，说明社区也意识到先前调度机制的不足。构建用户态调度框架将内核调度决策引入到用户态的确能够增加灵活性，但会导致更高的调度延迟与风险。微秒级调度解决了如上问题，但完全摒弃内核需要对大量的内核功能进行适配，这极大降低了运行时的兼容性。

针对如上发现，本文研究主要涉及如下部分：

1）典型应用画像与混部分析。本研究首先设计一套面向虚拟化环境的可观测系统，实现多维度、细粒度的应用性能监控监控，同时通过流量代理，实现应用QoS的劣化监测。随后本研究依据与企业合作的经验，选取了一批云场景中的典型应用，设计有无干扰下的混部实验，分析这些应用的资源使用倾向与干扰敏感度，了解这些典型应用的资源需求的同时，并进一步挖掘出更多的混部方案。

2）运行时调度可变的沙箱机制。本研究针对资源划分与任务调度上在混部场景下保障QoS的不足，设计实现了Control Zone，一种运行时调度可变的沙箱机制。该机制将混部策略抽象为资源声明、混部对象、调度策略的组合，并通过沙箱进行管理。相较于其他沙箱，Control Zone提供了虚拟机级别的资源隔离性，并且允许针对不同的混部场景对内核调度机制进行定制，在调度要求简单且性能要求高的混部场景，调度策略的定制能够仅发生在内核中，从而实现更高的效率，而在更复杂的混部场景，Control Zone也允许实现用户态调度程序，通过用户态与内核态的协作实现更灵活的调度策略。同时，Control Zone能够在运行时动态修改调度机制，从而能够适应混部场景及应用负载的变化。

3）资源感知调度系统实现。本研究综合上述可观测性系统与沙箱机制，设计了一种分层的资源感知调度系统。系统中的调度分两层实现，首先，不同混部方案以Control Zone的形式在系统中并行，这一层的调度以资源划分为主，即通过软硬件的资源隔离技术，尽可能地提升虚拟机的隔离性，从而保障有资源需求Control Zone的资源供给。而在Control Zone之中，依据不同混部场景的特点，来定制化调度策略，这一层主要以任务调度的形式来实现对于目标应用的QoS保证。同时，在运行过程中，可观测性系统会持续监测应用及虚拟机的性能，并为调度提供更多的辅助信息，用来随时更改Control Zone中的调度策略。

% \section{论文结构安排}

% 本文的主要内容分为七章，总体结构如图~\ref{fig:paper_organization}所示:

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=1.0\textwidth]{paper_organization}
%     \bicaption{\quad 本文组织架构}{\quad Paper Organization}
%     \label{fig:paper_organization}
% \end{figure}

% 第一章，包含研究背景与国内外相关研究，阐述了本文研究背景，即混部场景下的QoS保障，同时分析了当前研究在可观测性、资源划分与任务调度上的先进成果，最后提出了本研究的解决思路。

% 第二章，包含了本研究中的主要用的相关技术，其中eBPF技术主要在构建细粒度可观测性系统中使用，用来提取不同应用在系统维度的资源使用倾向。另一个则是Sched Ext技术，其所实现的插件化调度器为运行时可变内核调度奠定了基础。

% 第三章，

% 第四章，

% 第五章，

% 第六章，

% 第七章，