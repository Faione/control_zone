\chapter{引言}\label{chap:introduction}

\section{研究背景与意义}

% 问题 -> 
% - 数据中心规模不断扩大
% - 提升利用率的重要性
% 解决方式 -> 混部技术
% - LS 和 BE 应用天然具备混部
% - 通过混部的确解决了问题
% 局限 -> QOS
% 本质 -> 混部共享资源的竞争
% - CPU\Cache\Memory\IO\Net
% - AVX
% 研究现状
% - 劣化监测
% - 调度
% 本文

云计算提供了使用计算资源的便捷方式，其所具备弹性、安全等特征能够减轻云用户的管理负担。随着轻量级虚拟化技术的发展，LXD、Docker等容器技术让应用的分发与部署更加方便，加速了应用上云的进程。同时随着容器编排技术的发展，Kubernetes、OpenShift等提供了更便捷、灵活的运维方式，催生出DevOps概念并逐渐推广。企业与普通用户越来越倾向在云平台上部署应用，不断扩张的需求催生了巨大的云计算市场。而满足庞大的市场需求，云厂商不断扩大数据中心规模，据中国信息通信研究院中国算力发展指数白皮书（2023年）显示，2022年国内数据中心机架规模超过650万个标准机架，基础算力规模达到180EFlops，位居全球第二\citep{chinaict2023}。

数据中心的庞大规模带来了巨大的治理挑战。微软Azure在其内部调研中发现，数据中心每减少1\%的资源分配碎片率，每年就能节省近1亿美元\citep{hadary2020protean}。在数据中心规模不断扩张的背景下，高效利用数据中心计算资源、提高整体资源利用率成为云厂商关注的核心问题。

将互补类型的应用部署到相同物理机上，实现数据中心资源利用率的提升是混部技术的主要方式。依据应用对延迟的敏感度，通常将应用划分为延迟敏感性（LC）与尽力交付型（BE）两类。其中，LC应用通常为交互型应用，如在线购物等，这类应用对延时十分敏感，且需要保持运行。BE应用通常为离线应用，如大数据处理等，这类应用对延迟几乎没有要求，允许中断和重新运行。LC应用负载具有明显潮汐特征，向LC应用的各个空闲时段填充BE应用是混部技术提升资源利用率的核心。阿里云在实践中利用混部技术分别将集群的平均CPU利用率和内存资源利用率提升到了38.2\%和88.2\%\citep{guo2019limits}。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{scheduling_domain}
    \bicaption{\quad CPU拓扑}{\quad CPU Topology}
    \label{fig:scheduling_domain}
\end{figure}

资源竞争是混部技术下不可忽略的问题,分析这一问题首先需要了解资源的共享性与有限性。应用运行在不同的CPU上，CPU拓扑描述了核心之间的物理连接和组织方式，并反映出CPU资源的共享关系。随着CPU设计与制造技术的不断进步，当前出现如超线程技术(Hyper-threading)、非同一内存访问架构（NUMA）、大小核心架构等新特性，CPU拓扑也越来越复杂。常见的CPU拓扑如图~\ref{fig:scheduling_domain}所示，逻辑核位于CPU拓扑的最低一层，任务分时复用逻辑核资源，某一时刻仅有一个任务在运行，彼此几乎没有影响。超线程技术最早于2002年由Intel提出，通过增加部分片上资源使得一个物理核上能够运行多个逻辑核。超线程技术下的片上资源分布如图~\ref{fig:cpu_topology}所示，兄弟核心拥有各自独立的寄存器组与中断控制器，但彼此共享了执行单元、Cache和总线等其他资源。NUMA（非一致存储器访问）架构中存在多个CPU模块，每个CPU模块可以包含多个CPU，这些CPU拥有自己的本地内存与IO接口，但彼此共享了相同的内存总线与LLC，且在IO资源上相互竞争。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{cpu_topology}
    \bicaption{\quad Siblings片上共享资源 }{\quad Siblings on-chip shared resources}
    \label{fig:cpu_topology}
\end{figure}

现代服务器计算资源丰富，支持大量应用同时运行，然而局部硬件资源则相对有限，如片上资源、LLC、内存带宽、网络带宽等都存在明确的数量限制。混部技术向单一物理机上部署了更多的任务，增大了局部硬件资源竞争的概率，并容易造成应用QoS的劣化。如在网络子系统中，没有竞争到足够网络带宽的任务会积压在队列中，并导致应用延迟的激增。数据中心应用数量多、软件环境复杂，不同应用对资源的需求各不相同，一方面应用间存在隐含的资源竞争，另一方面应用竞争不同资源所引发的QoS劣化程度也存在差异。

资源竞争引发的QoS劣化体现在应用的性能指标上。云厂商提供了SLO来允许用户定义云应用的期望状态。SLO包含服务可用性、带宽等基础指标，以及每秒请求数量、尾延迟等业务性能指标。云厂商通过与用户协商SLO来提供云产品QoS的保证，并在违反SLO时进行补偿。应用的QoS劣化不仅会为云厂商带来经济损失，还会引发用户的流失，因此保障应用QoS是混部场景下云厂商核心需求。而了解应用的状态变化，实施精准的调度是解决混部场景中QoS保障问题的核心。混部场景下QoS保障相关研究通常从三个方向展开：

\begin{enumerate}
    \item 利用可观测性技术来对应用进行劣化监测，同时收集数据以进行画像分析。云厂商依赖可观测性基础设施来对数据中心进行持续监测。可观测性基础设施围绕不同的软件环境设计，如面向虚拟机、面向容器编排系统等。通过全面地指标监测实时收集数据，不仅可以及时发现应用的QoS劣化并进行预警，还能够利用丰富的指标数据来进行细致的画像分析，挖掘更多的混部机会。Google在2011年公布了混部集群监控数据集，同时阿里云也在2017年公开了一部分混部集群的监控数据集\citep{guo2019limits}。以上来自生产环境的脱敏数据集，促进了相关劣化监测的研究。
    \item 围绕资源隔离的混部场景QoS保障研究。资源隔离即通过软硬件手段来强化混部场景下应用在共享资源上的隔离性，防止因敏感资源的竞争导致的应用QoS劣化。不同资源隔离技术的区别在隔离资源的类型与粒度上，如使用Cgroup技术对CPU资源进行隔离，或使用traffic control技术\citep{hubert2002linux}对网络带宽进行隔离。同时，基于如Intel RDT\citep{guide2011intel}的硬件级资源隔离技术能实现更细粒度的隔离效果，如隔离末级缓存与内存带宽。组合这些隔离技术来制定不同的调度策略是基于资源隔离混部研究的主要方式。
    \item 围绕任务调度的混部场景QoS保障研究。任务在被调度到CPU上时才能执行，并能够进一步获取其他的硬件资源，因此CPU资源是大部分硬件资源分配的起点。相关研究从任务调度延时与灵活性上展开。其中微秒级调度机制通过远低于应用延迟要求的调度延时，及时分配CPU资源来避免QoS劣化。灵活的任务调度机制通过修改任务调度的逻辑，针对混部场景应用与硬件特性进行适配，从而更好地进行QoS保障。
\end{enumerate}

\section{国内外相关研究}

\subsection{数据中心可观测性与劣化监测研究现状}

% 可观测性系统
% - 定义
% - 实践

可观测性技术指通过指标监控、日志记录、链路追踪和其他数据收集手段来描述系统的状态，从而协助理解和诊断系统的行为和性能。在指标监控上，开源社区Prometheus\citep{brazil2018prometheus}定义了Metric，一种时序数据结构，以及围绕Metric的高效的编解码机制、灵活的数据存储方式和便捷的PromQL查询语言。此外，Prometheus社区也提供了采集系统的标准实现，包含Promethues Server、Node Exporter等核心组件，并与Grafana社区协作推出开源的数据展示服务。Promethues完全开源且致力于完善多语言Metric库支持。在各个厂商及开发者的共同参与下，Prometheus社区发展迅速，并逐渐成为指标采集领域的现行标准，被各个云厂商采用。

随软件架构的不断迭代，可观测性技术也在进步。微服务是数据中心常见的软件架构，一次请求调用链路往往跨越多个进程与服务器。传统的进程观测手段难以有效地对微服务进行观测，而为解决这一问题，Google在2010年提出了分布式链路追踪系统Dapper\citep{sigelman2010dapper}，用于对微服务应用进行性能分析。Dapper的设计如图~\ref{fig:dapper_trace}所示 其中Trace用来记录一次完整的链路追踪，Span用来记录追踪链路中的单个操作。Span记录的单个操作可以是一次函数的调用或者一段代码块，Dapper需要用户在进行代码插桩以指示Span的生成。在函数调用的过程中，Span会作为上下文的一部分传递，并自动地构建调用关系。微服务中一次函数调用也可以是一次远程过程调用（RPC），此时Dapper会将Span注入到网络报文的载荷中，让Span跨进程、服务器地传递下去。Span最终都会发送到Dapper的分析系统中，并根据树形关系重建得到完整的Trace，实现一次链路追踪。OpenTracing和OpenTelemetry等开源项目吸收了Dapper的核心思想，并在云原生社区中迅速推广。不同于Dapper的代码插桩，容器编排系统则通过Overlay Network来观测微服务性能。kubernetes中提供了CNI(Container Network Interface)\citep{k8s-network-plugins}来允许自定义容器网络模型。CNI项目如Cilium\citep{cilium}就基于eBPF、Envoy等技术\citep{ebpf,envoyproxy}构造Overlay Network，实现无侵入的网络性能监测与控制。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{dapper_span}
    \bicaption{\quad Dapper链路追踪流程（图片引用自文献\citep{sigelman2010dapper}）}{\quad Dapper tracking process (picture quoted from paper\citep{sigelman2010dapper})}
    \label{fig:dapper_trace}
\end{figure}

近年来随DevOps技术的发展，可观测性技术在云服务中占据了越来越重要的地位。而基于采集得到的指标分析应用性能劣化情况是可观测系统的主要应用场景。早期实践中，云厂商倾向于一些简单易懂的指标来反映应用的性能。如Google就使用CPI（Cycle Per Instruction）\citep{zhang2013cpi2}来反映应用的性能。CPI本身用于度量微观体系结构下的性能。应用正常运行时CPI通常会在一个小范围内波动。而当应用性能劣化时，CPI波动范围则会显著变化。CPI作为一个简易指标许多场景下有效，而在CPU频率较低时存在一定的误差，Li Yi等人\citep{yi2020cpi}在CPI基础上进一步优化得到RCPI，从而修正了误差。

数据中心的监控数据数量多、维度广，适合多种数据分析手段来进行QoS劣化监测。而近年来随AI技术的发展， 将AI和QoS劣化监测结合的研究也不断展开。如通过多种模型\citep{qiu2020firm, zhou2022aquatope, wang2022deepscaling, gan2021sage, ghafouri2020survey,zheng2020web,wu2019posterior}来对应用的QoS劣化进行预测，实现QoS劣化的提早发现和调度。其中
FIRM\citep{qiu2020firm}基于Kubernetes设计了一种两级的机器学习模型，能够识别集群中应用的QoS劣化。Di Wu\citep{wu2020data}则提出了一种数据特性感知潜在因素（DCALF）模型来实现高精度的QoS预测，并能够针对不同指标数据的特性有区别地处理。以上研究在调度延时不敏感、应用相对变化慢的集群维度都取得了相当显著劣化监测与调度效果。

\subsection{围绕资源隔离的混部场景QoS保障研究现状}

% 集群维度: 放置策略
% 单点维度: 细粒度分配

数据中心的资源通常可划分为集群资源与节点资源。其中，围绕集群资源隔离的研究可转化为任务放置问题。集群的各个节点都部署有可观测性基础设施，获取集群各个节点的总体资源、资源使用情况等信息。当有新任务提交并需要调度到某一个节点上时，调度器就综合各个节点的资源信息以及任务的资源需求求解出最优的节点。Protean\citep{hadary2020protean}是微软Azure实现的面向虚拟机混部的调度系统，能够在地域、地区、机柜等各个层次上逐层决策求解出最优节点，保证分配足够的资源给目标虚拟机，从而避免虚拟机的QoS劣化。

在节点资源隔离上，相关研究通过软硬件手段隔离不同应用的资源，避免关键资源上的竞争来实现应用的QoS保障。节点上有丰富的资源隔离机制，在软件上，Linux内核提供了丰富的资源隔离机制，如Cgroup、traffic control。在硬件上，硬件厂商提供了更细粒度的硬件隔离机制，如Intel RDT、ADM PQoS\citep{amdpqos}、ARM MPAM\citep{armmpam}等，来解决"吵闹邻居"问题\citep{xu2018dcat, maricq2018taming, rzadca2020autopilot, kwon2020dc}。

相关的QoS保障基于上述的软硬件资源隔离机制展开。Paragon\citep{delimitrou2013paragon}、Quasar\citep{delimitrou2014quasar}预先对应用进行观测，并基于观测数据建立分类模型。在应用调度时通过分类模型确认应用的类型，并利用类型信息来辅助进行后续的资源隔离决策。Heracles\citep{lo2015heracles}从应用资源敏感度的角度着手，首先分析了不同应用在不同负载下对于多种资源的敏感度，并在调度时依据分析结果优先保证敏感资源供给，从而实现应用的QoS保障。Parties\citep{chen2019parties}则进一步分析了如图~\ref{fig:parties_app_dif}所示更丰富的资源种类。同时不同于Heracles，Parties的调度通过在应用间拆借资源，实现在保障QoS的同时提升整体资源利用率。此外，CLITE\citep{patel2020clite}利用贝叶斯优化构建资源隔离模型，将多个LC应用与BE应用进行混部，并利用Intel MBA技术对内存带宽进行控制以保障LC应用的QoS需求。LIBRA\citep{zhang2021libra}则基于一种新型硬件节流机制，实现内存带宽的动态调控，并根据应用的需求变化动态调整，及时地保障内存带宽资源供给。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\textwidth]{parties_app_dif}
    \bicaption{\quad 不同资源干扰对应用性能的影响（图片引用自文献\citep{chen2019parties}）}{\quad Impact of diferent resource interference on application performance (picture quoted from paper\citep{chen2019parties})}
    \label{fig:parties_app_dif}
\end{figure}

\subsection{围绕任务调度的混部场景QoS保障研究}

% 内核任务调度
% 微秒级调度

围绕任务调度的QoS保障研究聚焦于CPU资源的分配，相关研究通常围绕调度机制的设计展开。调度机制的核心在于调度延时与调度策略，其中调度延时通常与Runtime的实现相关，而调度策略则取决于不同混部场景的调度目标。

CFS调度器\citep{pabla2009completely}是Linux中的默认任务调度器，于2009年提出，用来解决交互式应用与非交互式应用在调度上的公平性问题。CFS的核心在于CPU vruntime的计算与维护。CFS调度器为Run Queue中的每一个调度实体维护一个时间记账信息，并在每个时钟中断根据不同调度实体的优先级更新记账信息。优先级越高的调度实体，vruntime的积累速度越慢。而在每个调度循环中，CFS会选择Run Queue中vruntime最小的调度实体中的进程运行。CFS中使用了许多启发式的策略，在大多数场景下都能公平地进行调度。然而在混部场景中，CFS的部分启发式逻辑会导致严重的QoS劣化问题。如CFS调度器会为每个调度队列维护一个基准vruntime值，并将其赋予新创建的或新唤醒的进程。基准vruntime通常为Run Queue中的最小值，以便于新创建或新唤醒的进程优先执行。在LC与BE混部的场景中，为保障LC应用资源的优先供给，通常会提高LC应用的优先级，使得在每个调度循环中LC应用都有更大的几率被选中执行。然而此时如果有新创建的或新唤醒的进程，在CFS的启发式策略下这些进程会抢占高优先级的LC应用。当新创建或新唤醒的进程数量较多时，LC应用容易因得不到及时的调度而引发严重的QoS劣化。

为解决CFS存在的种种问题，Linux 6.6版本中引入了EEVDF来替换CFS。EEVDF\citep{stoica1995earliest}于1995年提出，算法中调度器会为每个进程维护一个虚拟截止时间，并在每次调度时选择最早截止时间的任务执行。不同于CFS，EEVDF的优先级设计考虑到了应用对延迟的不同需求，并引入了latency-nice机制。如图~\ref{fig:eevdf_scheduling}所示，为任务设置较高的latency-nice值会让任务总是获得长而少的时间片，对于计算密集型的应用而言，这样能够减少上下文切换的次数，从而有利于总体吞吐。而为应用设置较低latency-nice值则会让任务总是获得短而多的时间片，这样能够让CPU资源更快地分配，同时也更容易被调度。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{eevdf_scheduling}
    \bicaption{\quad EEVDF可变时间片机制}{\quad EEVDF Variable Time Slice Mechanism}
    \label{fig:eevdf_scheduling}
\end{figure}

针对CPU拓扑的变化，Linux 2.6中首次引入了调度域(Scheduler Domains)\citep{schedulerdomains}，用来协助处理多核处理器上的调度。如表~\ref{tab:resourcesharing}所示，调度域充分反映了围绕CPU的共享资源信息。Linux通过调度域这层抽象，让调度子系统感知CPU之间的拓扑关系，从而针对性地进行调度决策。然而Linux任务调度机制在适应CPU拓扑的变化上仍有不足。超线程技术中兄弟核心存在部分片上资源的共享，因此在兄弟核心上的任务容易因共享资源的竞争引发QoS的劣化。为解决在超线程技术上的混部QoS保障问题，Elfen\citep{yang2016elfen}设计了一种新的内核调度机制。Elfen首先实现了nanonap系统调用，允许进程快速地暂时释放CPU资源。随后，修改BE应用代码并插入探测函数，使得BE应用在运行过程中能够以微秒级间隔探测兄弟核心上任务的运行。而BE一旦发现兄弟核上有任务正在运行，就立即通过nanonap系统调用释放CPU资源。

针对AVX指令Linux任务调度也存在问题。AVX（Advanced Vector Extensions）指令最早由Intel提出，属于SIMD的一部分，旨在提高CPU的浮点运算性能，并于2011开始在Intel的实际产品中加入。实现中AVX指令涉及到CPU中加速单元的使用，而使用加速单元意味着更高的能耗。为防止过热，现代CPU通常会在加速单元工作时降低运行频率。而这一设计就引发了两个调度上的公平性问题。首先，当降频发生在任务切换时，由于频率的恢复需要一定的时间，这使得同一逻辑核上的先后两个任务存在相互相影响的可能。其次，兄弟核心共享了同一个物理核，物理核心的降频会使得所有兄弟核心受到影响。Linux任务调度机制并没有对如上两种情况进行特殊处理，因此存在调度公平性的问题。Gottschlag\citep{gottschlag2020avx}为解决这一问题，首先设计了一种监测手段，能够基于向量寄存器的使用情况来判断是否有AVX指令的执行。随后，Gottschlag修改Linux调度逻辑，通过微调vruntime来补偿受影响的任务，从而解决AVX指令引发的调度公平性问题。


\begin{table}[!htbp]
    \bicaption{\quad 调度域与共享资源}{\quad scheduler domains and resource sharing}% caption
    \label{tab:resourcesharing}
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.5}% row space 
    \centering
    \begin{tabular}{lc}
        \hline
        %\multicolumn{num_of_cols_to_merge}{alignment}{contents} \\
        %\cline{i-j}% partial hline from column i to column j
        调度域 & 共享资源\\
        \hline
        Core & 几乎隔离\\
        SMT & 执行单元、缓存、总线\\
        NUMA & 末级缓存、内存带宽、IO\\
        \hline
    \end{tabular}
\end{table}

另一种通过任务调度保障混部应用QoS的思路是微秒级调度\citep{ousterhout2019shenango,fried2020caladan,prekas2017zygos}，其核心在于将调度延时降低到LC应用允许的延迟范围内，并及时分配CPU资源来避免应用QoS劣化。Caladan\citep{fried2020caladan}实现了一种用户态的任务运行时，并通过DPDK（Data Plane Development Kit）、SPDK（Storage Performance Development Kit）解决硬件驱动问题。将操作系统的大部分功能实现到用户态，一方面不必隔离地址空间，大大减少了上下文切换的开销，另一方面打破Linux调度子系统的限制，能够更灵活地开发调度策略。Caladan使用集中式的调度模式，在负责调度的核心使用高精度时钟实现微秒级调度延时。同时，Caladan还能够从DPDK、SPDK中读取硬件资源的分配状况，这些额外信息能够有效辅助进行调度决策。

为特定工作负载量身定制调度策略能够显著改善如延时、吞吐量、能效等关键指标，然而在大型数据中心设计、实施和部署新的任务调度策略是一项艰巨的任务\citep{humphries2021ghost}。首先，调度子系统涉及Linux内核中的许多复杂机制，如复杂的同步原语及P-state（Processor State）控制等，独立开发的难度较大。其次，Linux内核开发不同于普通用户程序，不仅可用程序库较少，还对代码编写有严格的限制与规范。而在新调度策略部署时，由于Linux运行时无法修改调度策略，必须重新启动。服务器的重启意味着反复的任务迁移，在生产环境中难以接受。最后，Linux社区对于调度子系统的迭代相对保守，并期望普适的策略，一个高质量的调度器通常需要数十年的时间来不断完善\citep{agache2020firecracker}，如EEVDF从提出到正式并入主线内核就花费了29年。

为解决内核调度器在设计、实施和部署上的问题，加速内核调度机制迭代，Google提出了ghOSt\citep{humphries2021ghost}用户态调度器框架。ghOSt框架中包含三部分：内核调度类、用户态调度器及调度信息协议。ghOSt内核调度器在内核侧不断地更新任务状态，并按协议生成调度事件，用户态调度器通过特殊的系统调用消费事件并进行调度决策。用户态调度器的决策同样以事件的形式通过特殊系统调用提交给ghOSt内核调度器，并在内核侧进行实施。ghOSt调度框架在一定程度上解决了内核调度的灵活性问题，但由于频繁系统调用引发的上下文切换开销，很难实现较低的调度延时。eBPF技术提供了一种对Linux现有功能动态修改的思路，然而仅在网络子系统中有较成熟的实践。Meta与内核社区的开发者共同创建Sched Ext项目，提供了一种使用eBPF技术定制Linux调度机制的途径。相较于ghOSt，Sched Ext能完全运行在内核中，调度延时更低。同时，借助eBPF在其他子系统中的探测能力，Sched Ext能够与Caladan一样获取丰富的信息来辅助决策。

\section{论文的研究内容}

本文主要研究单点混部场景QoS保障问题，综合以上相关理论研究能够发现：

\begin{enumerate}

    \item \textbf{数据中心传统应用划分形式单一，容易忽略应用在资源上的倾向性与敏感性}。这一方面容易引发混部应用在隐含资源上竞争，另一方面也不利于系统资源的充分利用。在观测指标上，相关研究表明单一指标在部分场景中有效，但同时也依赖多维度、广泛的数据采集来对应用进行充分性能分析。最后，AI技术在集群调度上能够很好的发挥作用，但对于节点侧尤其是内核调度上，AI技术存在实施与部署上困难的问题。
    
    \item \textbf{任务调度机制是解决单点混部场景QoS保障问题的核心}。数据中心LC应用大部分为服务型应用，其资源使用倾向与敏感度随负载变化而变化。负载的动态性要求调度机制能够迅速的做出反应。基于资源隔离的调度程序一般在用户态实现，依赖系统调用来获取资源分配信息和进行资源隔离。同时，资源隔离机制如RDT技术等存在一定的生效延迟。这都限制了调度程序的调度频率，并容易引发调度的“乒乓效应”。不同于资源隔离，任务调度则通过CPU资源分配来间接地控制应用的资源使用。尽管调控粒度较粗，但由于在调度速度上的优势，任务调度能够更好地在单点上保障混部应用的QoS。
    
    \item \textbf{应用动态特性要求更灵活的任务调度机制，同时单一的任务调度机制无法适应多样的混部场景}。Linux内核追求普适的调度机制，并存在大量的启发式逻辑，难以针对特定混部场景进行调整与定制。其次，Linux调度机制在编译时确定且无法在运行时修改，在软硬件环境发生变化时不能快速调整。微秒级任务调度机制虽然QoS保障效果优秀，但由于绕过内核的设计与高度的定制，存在兼容性问题，无法在生产环境中大规模使用。最后，服务器资源丰富，能够同时运行大量应用，这些应用构成多样的混部场景。相关研究通常针对有限的场景，而单一的任务调度机制难以适配所有场景。

\end{enumerate}

综合上述对混部场景QoS保障研究的分析，本文总结了如下挑战并开展相应工作：

\begin{enumerate}

    \item \textbf{针对数据中心的软件环境复杂性挑战，展开典型应用监测与画像分析研究}。首先，结合对数据中心软件栈分析以及与云厂商的合作经验，选择了一批典型应用作为画像目标，并采用虚拟机作为应用的运行环境。随后，设计实现了一套可观测性系统，围绕虚拟机在Host、Hypervisor与App等多重维度，采集丰富的指标信息。最后，在可观测性系统的基础之上，展开针对典型应用的资源倾向与敏感度实验并给出画像结论。

    \item \textbf{针对当前任务调度机制在不同混部场景下的不足，展开混部场景导向的定制任务调度机制研究}。首先，从内核任务调度的相关配置上针对不同应用的需求，设计了响应度优先与吞吐量优先两种基础内核配置。随后，在Ext调度类的基础上设计了塔台（Control Tower）任务调度框架，并在此基础上，结合eBPF技术的监测能力进一步实现CPU资源感知与网络资源感知的任务调度策略。

    \item \textbf{针对单一调度机制与多样混部场景的挑战，设计实现受控空域（Contorl Zone），一种面向混部场景的调度动态可定制沙箱}。Control Zone基于KVM虚拟机实现，如图~\ref{fig:arch_dif}所示，相较于Firecracker\citep{agache2020firecracker}，Control Zone允许将Control Tower调度器与混部应用协同部署。一方面，能够针对不同混部场景自由地选择合适的Control Tower调度器。另一方面，能够随混部应用的变化在运行时对Control Tower调度器动态修改。同时，还支持通过软硬件手段来隔离不同Control Zone的资源。

\end{enumerate}

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{arch_dif_cz}
        \caption{Control Zone}
        \label{fig:arch_dif_cz}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{arch_dif_fc}
        \caption{Firecracker}
        \label{fig:arch_dif_fc}
    \end{subfigure}
\bicaption{\quad 沙箱结构差异}{\quad Sandbox Structure Differences}
\label{fig:arch_dif}
\end{figure}

\section{论文结构安排}

本文的主要内容分为六章，总体结构如图~\ref{fig:paper_organization}所示:

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{paper_organization}
    \bicaption{\quad 本文组织架构}{\quad Paper Organization}
    \label{fig:paper_organization}
\end{figure}

第1章，相关背景说明，首先，阐述了本文的主要背景，并提出了本文要解决的面向混部场景的QoS保障问题。随后，从可观测性与劣化监测、围绕资源隔离的混部场景QoS保障、围绕任务调度的混部场景QoS保障三个方面分析了国内外研究现状。最后，阐述了本文的主要开展的工作，以及其对当前混部场景下QoS保障的贡献。

第2章，本文中所采用的技术说明，首先，分析了经典的Linux调度子系统的构成以及任务调度的决策过程。其次，介绍了本文中使用到的eBPF技术，阐述其核心特点，以及相较于内核模块等传统内核功能扩展技术的差异。随后，介绍了Sched Ext项目，一种插件化内核调度器补丁集，说明了其实现的原理，为本文后续后续BPF Scheduler的实现进行铺垫。最后，介绍了沙箱技术以及相关的实现。

第3章，典型应用观测与画像分析，首先，介绍了云场景典型应用的选择方式及所挑选的应用。其次，针对虚拟机这一特殊场景，阐述了多维度指标采集可观测性系统的设计与实现。最后，分别对基准性能实验与干扰敏感度实验进行实验设计的阐述与最后的画像结果分析。

第4章，混部场景导向的任务调度机制定制，包含内核配置定制、Control Tower任务调度框架两个方面。在内核调度配置上，设计了响应度优先与吞吐量优先两种内核配置。在Control Tower任务调度框架上，首先阐述了设计目标和实现原理，随后扩展实现了CPU资源感知与网络资源感知两种调度策略。

第5章，Control Zone的设计与实现。在第3、4章的基础上，设计实现了一种调度动态可定制沙箱。一方面能够通过内核调度定制与Control Tower任务调度框架，针对混部场景选择合适的任务调度机制。另一方面基于虚拟化，实现不同调度机制在同一物理机上共存。

第6章，总结与展望。首先对于本文针对混部场景QoS保障问题的三个工作进行总结，分析了本文工作的效果与不足之处。随后，对利用eBPF观测能力与Ext调度类灵活性在更多混部场景定制Control Tower调度策略进行了展望。