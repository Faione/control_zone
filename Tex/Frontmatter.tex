%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-

\maketitle% 生成中文封面
\MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
\makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
\intobmk\chapter*{摘\quad 要}% 显示在书签但不显示在目录
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

% 背景 -> 调度是核心解决方式
% 混部场景挑战
% 解决挑战的方式
% 最终效果


混合部署是当前数据中心提升资源利用率的有效手段，通过应用对延迟的敏感度差异，可以将应用区分为延迟敏感型与尽力交付型，并部署到同一台服务器中。混合部署允许任务的并发，从而能在一定程度上提升整体资源的利用率，但由于服务器整体资源有限，并发通常会导致资源竞争，此时可以牺牲尽力交付型应用，来优先保障延迟敏感型应用的服务质量。而要实现上述目标，就依赖一定的资源隔离手段与调度机制。

本文首先对数据中心典型应用进行画像分析，分析不同应用的资源使用特征与干扰敏感度，了解应用对于运行环境的需求，以及可能存在的资源竞争场景，协助制定混部方案。其次，从内核配置与资源感知两个方面设计了针对不同场景的定制调度方案，来解决不同混部场景下的QoS保障问题。最后，为解决不同内核配置以及不同调度器在服务器上并存的需求，设计实现了Control Zone，一种面向混部场景的沙箱系统。

Control Zone基于虚拟机实现，提供了丰富的资源隔离配置，来对混部应用所需的资源进行充分的隔离与保护，同时，Control Zone支持运行时可变的调度器，通过将内核调度器容器化，能够方便地针对不同的混部方案进行选择与动态更新。而针对典型的混部场景，本文设计实现了资源感知调度策略，能根据CPU、网络等资源的使用情况来自动地进行任务调度，实现对高优先级应用的QoS保障。最后，本文还设计实现了一套围绕虚拟机的可观测性系统，能够实时地采集丰富的虚拟机指标数据，辅助进行性能分析。

% 具体数字

通过对内核以及虚拟机运行时的优化，Control Zone虚拟机启动事件能够控制在380ms以内，达到了与CloudHypervisor相近的水平。而通过场景适配的内核配置，其中响应度优先内核能够在混部场景中间低负载时的LC应用延迟降低50.6\%，而吞吐量优先内核则能够在CPU敏感应用单独部署时，将吞吐量提高了166.42\%。而在资源感知的BPF调度策略中，使用CPU资源感知的调度策略，能够在保障整体CPU资源使用率的同时，使得高优先级应用的资源使用率接近其单独部署下的水平，实现了混部场景下LC应用低负载时79.6\%的延迟降低，并在高负载时仍有33.7\%的延迟降低效果。

\keywords{数据中心，混合部署，内核调度，eBPF，服务质量}% 中文关键词
%-
%-> 英文摘要
%-
\intobmk\chapter*{Abstract}% 显示在书签但不显示在目录


Hybrid deployment is an effective means for current data centers to enhance resource utilization. By distinguishing applications into latency-sensitive and best-effort delivery types based on their sensitivity to latency, they can be deployed on the same server. Hybrid deployment allows for task concurrency, thereby improving overall resource utilization to some extent. However, due to the limited overall resources of servers, concurrency typically leads to resource contention. In such cases, sacrificing best-effort delivery applications can prioritize the service quality of latency-sensitive applications. Achieving these goals relies on certain resource isolation mechanisms and scheduling mechanisms.

This article first profiles typical applications in data centers, analyzing the resource usage characteristics and interference sensitivity of different applications to understand their requirements for the operating environment and potential scenarios of resource contention, assisting in devising hybrid deployment schemes. Secondly, it designs customized scheduling schemes for different scenarios from the perspectives of kernel configuration and resource awareness to address quality of service (QoS) assurance issues in different hybrid deployment scenarios. Finally, to meet the requirements of different kernel configurations and coexistence of different schedulers on servers, it designs and implements Control Zone, a sandbox system tailored for hybrid deployment scenarios.

Control Zone, implemented based on virtual machines, provides rich resource isolation configurations to adequately isolate and protect the resources required by hybrid applications. Additionally, Control Zone supports runtime-variable schedulers, making it convenient to select and dynamically update kernel schedulers for different hybrid deployment schemes by containerizing the kernel scheduler. For typical hybrid deployment scenarios, this article designs and implements resource-aware scheduling policies that automatically schedule tasks based on the usage of resources such as CPU and network, achieving QoS assurance for high-priority applications. Finally, it designs and implements a set of observability systems centered around virtual machines, capable of real-time collection of rich virtual machine metric data to assist in performance analysis.

Through optimization of the kernel and virtual machine runtime, Control Zone achieves virtual machine startup times within 380ms, comparable to levels achieved by CloudHypervisor. With scenario-adapted kernel configurations, the responsiveness-oriented kernel reduces latency of LC applications by 50.6\% in low-load hybrid scenarios, while the throughput-oriented kernel increases throughput by 166.42\% when CPU-sensitive applications are deployed separately. In the resource-aware BPF scheduling strategy, utilizing CPU resource-aware scheduling policies not only ensures overall CPU resource utilization but also brings latency reductions of 79.6\% for LC applications in low-load hybrid scenarios and 33.7\% in high-load scenarios compared to their standalone deployments.

\KEYWORDS{Data center, Co-Location, Kernel Scheduling, eBPF, Quality of Service}% 英文关键词

\pagestyle{enfrontmatterstyle}%
\cleardoublepage\pagestyle{frontmatterstyle}%

%---------------------------------------------------------------------------%
