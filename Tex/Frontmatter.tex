%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-

\maketitle% 生成中文封面
\MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
\makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
\intobmk\chapter*{摘\quad 要}% 显示在书签但不显示在目录
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

% 背景 -> 调度是核心解决方式
% 混部场景挑战
% 解决挑战的方式
% 最终效果

混部技术是当前云厂商提升数据中心利用率的主要方式，但也引发了应用之间的资源竞争并导致关键应用的QoS劣化。通常云厂商会与用户协定SLO来提供服务的的质量保证，而应用的QoS劣化一方面会导致协议违约产生经济损失，另一方面也会引发用户的流失，因此混部场景下的QoS保障是云厂商的核心需求。常见的混部场景QoS保障的措施包括劣化监测、资源隔离与任务调度，其中任务调度机制由于在调控速度与精度上的优势，是解决单物理机中混部场景QoS保障问题的核心。

混部场景下的任务调度机制设计存在三大挑战，（1）混部场景软硬件环境复杂，调度机制一方面需要满足应用的不同需求，如延迟、吞吐量等，另一方面还需要需要匹配硬件的不同特性，如SMT、NUMA等。（2）混部场景中应用类型、负载并不固定，如服务型应用的负载就会随时间波动，调度机制需要感知变化并及时调整。（3）服务器资源丰富，同时运行着大量应用，并构成多样的混部场景，单一的调度机制无法满足所有场景的需求。

为解决上述挑战，本研究（1）针对云场景中的7种典型应用展开画像分析，设计并实现了一套面向虚拟机的多维度指标监测系统，分析应用在资源使用倾向与敏感度上的差异。（2）展开混部场景导向的任务调度策略定制研究，从调度子系统配置与可扩展调度类出发，其中，响应度优先配置能够最高降低混部应用39.2\%延迟，吞吐量优先内核最高能够提升混部应用165.2\%的执行速度。同时，基于可扩展调度类设计了Control Tower任务调度框架，其中CPU感知调度策略实现了混部场景下关键应用90.4\%的延迟降低，并在超线程场景中仍然有最高71.2\%的延迟降低效果，使得在混部场景中高优先应用能达到与单独部署相近的性能（3）设计实现Control Zone，一种面向混部场景的调度动态可定制沙箱，提供了在一台物理机上基于虚拟化实现的多种调度机制共存的方案，支持将混部的应用、匹配的调度器一同打包部署，并且调度器能够在运行时动态变换以适应混部场景软硬件环境的变化，沙箱启动延时在370ms内。同时，通过裁切内核的方式，使得网络服务应用即便在虚拟化开销下，仍然能够实现最高38.5\%的延迟降低。

\keywords{数据中心，混合部署，内核调度，eBPF，服务质量}% 中文关键词
%-
%-> 英文摘要
%-
\intobmk\chapter*{Abstract}% 显示在书签但不显示在目录

Co-location technology is currently the main way for cloud vendors to improve data center utilization, but it also triggers resource competition between applications and leads to QoS degradation of key applications. Usually cloud vendors will agree on SLO with users to provide quality assurance of services. On the one hand, QoS degradation of applications will lead to economic losses due to agreement breaches, and on the other hand, it will also cause the loss of users. Therefore, the QoS guarantee in the co-location scenario is The core needs of cloud vendors. Common QoS guarantee measures in co-location scenarios include degradation monitoring, resource isolation and task scheduling. Among them, the task scheduling mechanism is the core to solve the QoS guarantee problem in co-location scenarios in a single physical machine due to its advantages in control speed and accuracy.

There are three major challenges in the design of task scheduling mechanisms in co-location scenarios. (1) The software and hardware environment of co-location scenarios are complex. On the one hand, the scheduling mechanism needs to meet the different needs of applications, such as latency, throughput, etc., and on the other hand, it also needs to match Different characteristics of hardware, such as SMT, NUMA, etc. (2) In co-location scenarios, application types and loads are not fixed. For example, the load of service-oriented applications will fluctuate over time, and the scheduling mechanism needs to sense changes and adjust in time. (3) Servers are rich in resources and run a large number of applications at the same time, forming a variety of co-location scenarios. A single scheduling mechanism cannot meet the needs of all scenarios.

In order to solve the above challenges, this study (1) carried out portrait analysis on 7 typical applications in cloud scenarios, designed and implemented a multi-dimensional indicator monitoring system for virtual machines, and analyzed the resource usage tendency and sensitivity of applications. difference. (2) Carry out research on task scheduling strategy customization oriented to co-location scenarios, starting from the scheduling subsystem configuration and scalable scheduling class. Among them, the responsiveness-first configuration can reduce the delay of co-location applications by up to 39.2\%, and the throughput-priority kernel can reduce the latency of co-location applications by up to 39.2\%. Improve the execution speed of co-location applications by 165.2\%. At the same time, the Control Tower task scheduling framework is designed based on the scalable scheduling class. The CPU-aware scheduling strategy achieves a 90.4\% latency reduction for key applications in a co-location scenario, and still achieves a maximum 71.2\% latency reduction in a hyper-threading scenario. The effect enables high-priority applications in co-location scenarios to achieve performance similar to that of individual deployments (3) Design and implement Control Zone, a dynamically customizable sandbox for scheduling in co-location scenarios, which provides virtualization-based virtualization on a physical machine The implemented coexistence scheme of multiple scheduling mechanisms supports packaging and deployment of co-location applications and matching schedulers, and the scheduler can be dynamically changed at runtime to adapt to changes in the software and hardware environment of co-location scenarios, and sandbox startup delays Within 370ms. At the same time, by cutting off the core, network service applications can still achieve up to 38.5\% latency reduction compared to direct deployment on the Host, even under virtualization overhead.


\KEYWORDS{Data center, Co-Location, Kernel Scheduling, eBPF, Quality of Service}% 英文关键词

\pagestyle{enfrontmatterstyle}%
\cleardoublepage\pagestyle{frontmatterstyle}%

%---------------------------------------------------------------------------%
